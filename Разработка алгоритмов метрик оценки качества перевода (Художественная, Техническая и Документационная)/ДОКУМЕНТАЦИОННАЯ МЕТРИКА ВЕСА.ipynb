{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Средние значения для категории 'Юридический' (EN-RU):\n",
      "BLEU: 0.2898769550783061\n",
      "ROUGE-1: 0.6144939450422369\n",
      "METEOR: 0.4644098224052673\n",
      "\n",
      "Средние значения для категории 'Юридический' (RU-EN):\n",
      "BLEU: 0.2522891250577603\n",
      "ROUGE-1: 0.5848155031828365\n",
      "METEOR: 0.43632305016428313\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Загрузка данных\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "# Функция для расчета средних значений по выбранной категории и метрикам\n",
    "def compute_legal_means(direction):\n",
    "    # Фильтрация данных по направлению и категории \"Юридический\"\n",
    "    filtered_df = df[(df['Направление перевода'] == direction) & \n",
    "                     (df['Категория'] == 'Юридический')]\n",
    "\n",
    "    # Вычисление средних значений для BLEU, ROUGE-1 и METEOR\n",
    "    bleu_mean = filtered_df['BLEU'].mean()\n",
    "    rouge_1_mean = filtered_df['ROUGE-1'].mean()\n",
    "    meteor_mean = filtered_df['METEOR'].mean()\n",
    "\n",
    "    print(f\"\\nСредние значения для категории 'Юридический' ({direction}):\")\n",
    "    print(f\"BLEU: {bleu_mean}\")\n",
    "    print(f\"ROUGE-1: {rouge_1_mean}\")\n",
    "    print(f\"METEOR: {meteor_mean}\")\n",
    "\n",
    "# Средние значения для EN-RU\n",
    "compute_legal_means('EN-RU')\n",
    "\n",
    "# Средние значения для RU-EN\n",
    "compute_legal_means('RU-EN')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En-Ru Artistic Metric. Документационная метрика с английского на русский:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En-Ru веса для метрики BLEU 0.21177749679539343\n",
      "En-Ru веса для метрики ROGUE: 0.448935271318193\n",
      "En-Ru веса для метрики METEOR: 0.3392872318864136\n",
      "En-Ru сумма всех весов: 1.0\n",
      "En-Ru документационная метрика: 0.49482574497082177\n"
     ]
    }
   ],
   "source": [
    "# Среднее арифметическое метрик оценки качества перевода документационных текстов \n",
    "er_bleu_score = 0.2898769550783061\n",
    "er_rouge1_score = 0.6144939450422369\n",
    "er_meteor_score = 0.4644098224052673\n",
    "\n",
    "\n",
    "# Функция для вычисления взвешенной метрики на основе предоставленных BLEU, METEOR и ROUGE-1\n",
    "def calculate_weighted_metric(er_bleu, er_meteor, er_rouge1):\n",
    "    # Вычисление суммы всех метрик\n",
    "    er_k = er_bleu + er_meteor + er_rouge1\n",
    "\n",
    "    # Вычисление весов для каждой метрики\n",
    "    er_w_bleu = er_bleu / er_k\n",
    "    er_w_rouge1 = er_rouge1 / er_k\n",
    "    er_w_meteor = er_meteor / er_k\n",
    "   \n",
    "\n",
    "    # Вычисление суммы весов (должно быть 1)\n",
    "    er_total_weight = er_w_bleu + er_w_meteor + er_w_rouge1\n",
    "\n",
    "    # Вычисление новой документационной метрики с весами\n",
    "    er_art = er_w_bleu * er_bleu + er_w_meteor * er_meteor + er_w_rouge1 * er_rouge1\n",
    "\n",
    "    return er_w_bleu, er_w_meteor, er_w_rouge1, er_total_weight, er_art\n",
    "\n",
    "\n",
    "\n",
    "# Вызов функции для вычисления весов и взвешенной метрики\n",
    "er_w_bleu, er_w_meteor, er_w_rouge1, er_total_weight, er_art = calculate_weighted_metric(er_bleu_score, er_meteor_score, er_rouge1_score)\n",
    "\n",
    "print(\"En-Ru веса для метрики BLEU\", er_w_bleu)\n",
    "print(\"En-Ru веса для метрики ROGUE:\", er_w_rouge1)\n",
    "print(\"En-Ru веса для метрики METEOR:\", er_w_meteor)\n",
    "print(\"En-Ru сумма всех весов:\", er_total_weight)\n",
    "print(\"En-Ru документационная метрика:\", er_art)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ru-En Artistic Metric. Документационная метрика с русского на английский:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ru-En веса для метрики BLEU 0.1981181415608798\n",
      "Ru-En веса для метрики ROGUE: 0.45924516413479216\n",
      "Ru-En веса для метрики METEOR: 0.3426366943043281\n",
      "Ru-En сумма всех весов: 1.0\n",
      "Ru-En документационная метрика: 0.4680570318973082\n"
     ]
    }
   ],
   "source": [
    "# Среднее арифметическое метрик оценки качества перевода документационных текстов \n",
    "re_bleu_score = 0.2522891250577606\n",
    "re_rouge1_score = 0.5848155031828365\n",
    "re_meteor_score = 0.43632305016428313\n",
    "\n",
    "\n",
    "# Функция для вычисления взвешенной метрики на основе предоставленных BLEU, METEOR и ROUGE-1\n",
    "def calculate_weighted_metric(re_bleu, re_meteor, re_rouge1):\n",
    "    # Вычисление суммы всех метрик\n",
    "    re_k = re_bleu + re_meteor + re_rouge1\n",
    "\n",
    "    # Вычисление весов для каждой метрики\n",
    "    re_w_bleu = re_bleu / re_k\n",
    "    re_w_rouge1 = re_rouge1 / re_k\n",
    "    re_w_meteor = re_meteor / re_k\n",
    "   \n",
    "\n",
    "    # Вычисление суммы весов (должно быть 1)\n",
    "    re_total_weight = re_w_bleu + re_w_meteor + re_w_rouge1\n",
    "\n",
    "    # Вычисление новой документационной метрики с весами\n",
    "    re_art = re_w_bleu * re_bleu + re_w_meteor * re_meteor + re_w_rouge1 * re_rouge1\n",
    "\n",
    "    return re_w_bleu, re_w_meteor, re_w_rouge1, re_total_weight, re_art\n",
    "\n",
    "\n",
    "\n",
    "# Вызов функции для вычисления весов и взвешенной метрики\n",
    "re_w_bleu, re_w_meteor, re_w_rouge1, re_total_weight, re_art = calculate_weighted_metric(re_bleu_score, re_meteor_score, re_rouge1_score)\n",
    "\n",
    "print(\"Ru-En веса для метрики BLEU\", re_w_bleu)\n",
    "print(\"Ru-En веса для метрики ROGUE:\", re_w_rouge1)\n",
    "print(\"Ru-En веса для метрики METEOR:\", re_w_meteor)\n",
    "print(\"Ru-En сумма всех весов:\", re_total_weight)\n",
    "print(\"Ru-En документационная метрика:\", re_art)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Artistic Metric Weights. Среднее арифметическое весов документационной метрики."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ru-En веса для метрики BLEU 0.20494781917813662\n",
      "Ru-En веса для метрики ROGUE: 0.4540902177264926\n",
      "Ru-En веса для метрики METEOR: 0.34096196309537086\n",
      "Ru-En сумма всех весов: 1.0\n",
      "Ru-En документационная метрика: 0.481441388434065\n"
     ]
    }
   ],
   "source": [
    "art_bleu = (er_w_bleu + re_w_bleu) / 2\n",
    "art_rouge = (er_w_rouge1 + re_w_rouge1) / 2\n",
    "art_meteor = (er_w_meteor + re_w_meteor) / 2\n",
    "art_total_weight = (er_total_weight+ re_total_weight) / 2\n",
    "art_average = (er_art + re_art) / 2\n",
    "\n",
    "print(\"Ru-En веса для метрики BLEU\", art_bleu)\n",
    "print(\"Ru-En веса для метрики ROGUE:\", art_rouge)\n",
    "print(\"Ru-En веса для метрики METEOR:\", art_meteor)\n",
    "print(\"Ru-En сумма всех весов:\", art_total_weight)\n",
    "print(\"Ru-En документационная метрика:\", art_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрика оценки качества перевода документационных текстов с уникальными весами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bleu_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Вычисление суммы всех метрик\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[43mbleu_score\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28msum\u001b[39m(rouge[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrouge-1\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m rouge \u001b[38;5;129;01min\u001b[39;00m scores) \u001b[38;5;241m+\u001b[39m score \n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Уникальные веса для каждой метрики оценки качества перевода документационных текстов\u001b[39;00m\n\u001b[0;32m      5\u001b[0m w_bleu \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'bleu_score' is not defined"
     ]
    }
   ],
   "source": [
    "# Вычисление суммы всех метрик\n",
    "k = bleu_score + sum(rouge['rouge-1']['f'] for rouge in scores) + score \n",
    "\n",
    "# Уникальные веса для каждой метрики оценки качества перевода документационных текстов\n",
    "w_bleu = 0.2\n",
    "w_rouge_1 = 0.45\n",
    "w_score = 0.35\n",
    "\n",
    "# Вычисление метрики оценки качества перевода документационных текстов с уникальными весами\n",
    "art_met = w_bleu * bleu_score + w_rouge_1 * sum(rouge['rouge-1']['f'] for rouge in scores) + w_score * score \n",
    "\n",
    "# Результаты оценки качества перевода документационного текста\n",
    "print(\"Оценка качества перевода документационного текста:\", art_met)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
