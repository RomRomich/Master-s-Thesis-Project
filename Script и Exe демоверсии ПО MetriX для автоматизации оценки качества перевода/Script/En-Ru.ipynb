{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk  # Импорт библиотеки Natural Language Toolkit (NLTK)\n",
    "import csv  # Импорт модуля для работы с файлами CSV\n",
    "\n",
    "from nltk.corpus import stopwords  # Импорт списка стоп-слов из NLTK\n",
    "from nltk.stem import SnowballStemmer  # Импорт стеммера из NLTK\n",
    "from nltk.tokenize import word_tokenize  # Функция для токенизации текста\n",
    "from nltk.translate.bleu_score import corpus_bleu  # Функция для вычисления BLEU\n",
    "from nltk.translate.meteor_score import meteor_score  # Функция для вычисления METEOR\n",
    "from rouge import Rouge  # Класс для вычисления метрики ROUGE\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание экземпляра стеммера\n",
    "stemmer = SnowballStemmer(\"russian\")\n",
    "\n",
    "# Получение списка стоп-слов на русском языке\n",
    "stop_words = set(stopwords.words('russian'))\n",
    "\n",
    "# Функция предобработки текста\n",
    "def preprocess_text(text):\n",
    "    # Токенизация текста\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Удаление стоп-слов\n",
    "    filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "    \n",
    "    # Стемминг токенов\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in filtered_tokens]\n",
    "    \n",
    "    # Ограничение количества токенов до 512\n",
    "    limited_tokens = stemmed_tokens[:512]\n",
    "    \n",
    "    # Склеивание токенов обратно в строку\n",
    "    preprocessed_text = ' '.join(limited_tokens)\n",
    "    \n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для загрузки текста из файла с предобработкой\n",
    "def load_text_preprocessed(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "        # Предобработка загруженного текста\n",
    "        preprocessed_text = preprocess_text(text)\n",
    "    return preprocessed_text\n",
    "\n",
    "# Загрузка предобработанного эталонного текста\n",
    "reference_text = load_text_preprocessed('reference.txt')\n",
    "\n",
    "# Загрузка предобработанного переведенного текста\n",
    "translated_text = load_text_preprocessed('translated.txt')\n",
    "\n",
    "# Токенизация текстов\n",
    "reference_tokens = word_tokenize(reference_text.lower())\n",
    "translated_tokens = word_tokenize(translated_text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 1.821831989445342e-231\n",
      "ROUGE scores: [{'rouge-1': {'r': 1.0, 'p': 1.0, 'f': 0.999999995}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 1.0, 'p': 1.0, 'f': 0.999999995}}]\n",
      "METEOR score: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "# Вычисление BLEU-метрики\n",
    "bleu_score = corpus_bleu([[reference_tokens]], [translated_tokens])\n",
    "\n",
    "# Создание экземпляра класса Rouge\n",
    "rouge = Rouge()\n",
    "\n",
    "# Вычисление метрики ROUGE\n",
    "scores = rouge.get_scores(translated_text, reference_text)\n",
    "\n",
    "# Оценка качества перевода с помощью метрики METEOR\n",
    "score = meteor_score([reference_tokens], translated_tokens)\n",
    "\n",
    "# Вывод результатов\n",
    "print(\"BLEU score:\", bleu_score)\n",
    "print(\"ROUGE scores:\", scores)\n",
    "print(\"METEOR score:\", score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее арифметическое из всех метрик: 0.499999998\n"
     ]
    }
   ],
   "source": [
    "# Вычисление среднего арифметического из всех метрик\n",
    "average = (bleu_score + sum(rouge['rouge-1']['f'] for rouge in scores) + sum(rouge['rouge-2']['f'] for rouge in scores) + sum(rouge['rouge-l']['f'] for rouge in scores) + score) / 5\n",
    "\n",
    "# Вывод среднего арифметического из всех метрик\n",
    "print(\"Среднее арифметическое из всех метрик:\", average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оценка качества перевода художественного текста: 0.6999999975\n"
     ]
    }
   ],
   "source": [
    "# Вычисление суммы всех метрик\n",
    "k = bleu_score + sum(rouge['rouge-1']['f'] for rouge in scores) + score \n",
    "\n",
    "# Уникальные веса для каждой метрики оценки качества перевода художественных текстов\n",
    "w_bleu = 0.1\n",
    "w_rouge_1 = 0.5\n",
    "w_score = 0.4\n",
    "\n",
    "# Вычисление метрики оценки качества перевода художественных текстов с уникальными весами\n",
    "art_met = w_bleu * bleu_score + w_rouge_1 * sum(rouge['rouge-1']['f'] for rouge in scores) + w_score * score \n",
    "\n",
    "# Результаты оценки качества перевода художественного текста\n",
    "print(\"Оценка качества перевода художественного текста:\", art_met)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_metrics_to_csv(metrics, csv_file):\n",
    "    # Проверяем, существует ли файл CSV\n",
    "    file_exists = os.path.exists(csv_file)\n",
    "    \n",
    "    # Открываем файл CSV в режиме добавления данных\n",
    "    with open(csv_file, 'a', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=metrics.keys())\n",
    "        \n",
    "        # Если файл не существует, записываем заголовки полей\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "        \n",
    "        # Записываем значения метрик в файл CSV\n",
    "        writer.writerow(metrics)\n",
    "\n",
    "# Пример использования:\n",
    "metrics = {\n",
    "    'BLEU score': bleu_score,\n",
    "    'ROUGE scores': scores,\n",
    "    'METEOR score': score,\n",
    "    'Среднее арифметическое из всех метрик': average,\n",
    "    'Оценка качества перевода': art_met\n",
    "}\n",
    "\n",
    "# Путь к файлу CSV\n",
    "csv_file = 'En-Ru metrics.csv'\n",
    "\n",
    "# Сохраняем метрики в файл CSV\n",
    "save_metrics_to_csv(metrics, csv_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BLEU score': '1.821831989445342e-231', 'ROUGE scores': \"[{'rouge-1': {'r': 1.0, 'p': 1.0, 'f': 0.999999995}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 1.0, 'p': 1.0, 'f': 0.999999995}}]\", 'METEOR score': '0.5', 'Среднее арифметическое из всех метрик': '0.499999998', 'Оценка качества перевода': '0.6999999975'}\n"
     ]
    }
   ],
   "source": [
    "def load_metrics_from_csv(csv_file):\n",
    "    metrics = []\n",
    "    with open(csv_file, 'r', newline='', encoding='utf-8') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            metrics.append(row)\n",
    "    return metrics\n",
    "\n",
    "# Пример использования:\n",
    "csv_file = 'En-Ru metrics.csv'\n",
    "\n",
    "# Загружаем данные из файла CSV\n",
    "metrics = load_metrics_from_csv(csv_file)\n",
    "\n",
    "# Отображаем значения метрик\n",
    "for entry in metrics:\n",
    "    print(entry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее арифметическое для BLEU score: 1.821831989445342e-231\n",
      "Среднее арифметическое для METEOR score: 0.5\n",
      "Среднее арифметическое для ROUGE-1: 0.999999995\n",
      "Среднее арифметическое для ROUGE-2: 0.0\n",
      "Среднее арифметическое для ROUGE-L: 0.999999995\n",
      "Среднее арифметическое из всех метрик: 0.499999998\n",
      "Оценка качества перевода: 0.6999999975\n"
     ]
    }
   ],
   "source": [
    "def load_metrics_from_csv(csv_file):\n",
    "    metrics = []\n",
    "    with open(csv_file, 'r', newline='', encoding='utf-8') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            metrics.append(row)\n",
    "    return metrics\n",
    "\n",
    "def calculate_average(metrics):\n",
    "    bleu_scores = []\n",
    "    meteor_scores = []\n",
    "    rouge_1_scores = []\n",
    "    rouge_2_scores = []\n",
    "    rouge_l_scores = []\n",
    "    average_scores = []\n",
    "    art_met_scores = []  # Массив для хранения значений art_met\n",
    "    \n",
    "    for entry in metrics:\n",
    "        bleu_scores.append(float(entry['BLEU score']))\n",
    "        meteor_scores.append(float(entry['METEOR score']))\n",
    "        \n",
    "        # ROUGE scores в формате строки, преобразуем в словарь\n",
    "        rouge_scores = eval(entry['ROUGE scores'])\n",
    "        \n",
    "        rouge_1_scores.append(rouge_scores[0]['rouge-1']['f'])\n",
    "        rouge_2_scores.append(rouge_scores[0]['rouge-2']['f'])\n",
    "        rouge_l_scores.append(rouge_scores[0]['rouge-l']['f'])\n",
    "        \n",
    "        average_scores.append(float(entry['Среднее арифметическое из всех метрик']))\n",
    "        art_met_scores.append(float(entry['Оценка качества перевода']))  # Добавляем значение art_met из CSV\n",
    "    \n",
    "    # Вычисляем среднее арифметическое для каждой метрики\n",
    "    average_bleu = sum(bleu_scores) / len(bleu_scores)\n",
    "    average_meteor = sum(meteor_scores) / len(meteor_scores)\n",
    "    average_rouge_1 = sum(rouge_1_scores) / len(rouge_1_scores)\n",
    "    average_rouge_2 = sum(rouge_2_scores) / len(rouge_2_scores)\n",
    "    average_rouge_l = sum(rouge_l_scores) / len(rouge_l_scores)\n",
    "    average = sum(average_scores) / len(average_scores)\n",
    "    average_art_met = sum(art_met_scores) / len(art_met_scores)  # Среднее для art_met\n",
    "    \n",
    "    return average_bleu, average_meteor, average_rouge_1, average_rouge_2, average_rouge_l, average, average_art_met\n",
    "\n",
    "# Пример использования:\n",
    "csv_file = 'En-Ru metrics.csv'\n",
    "\n",
    "# Загружаем данные из файла CSV\n",
    "metrics = load_metrics_from_csv(csv_file)\n",
    "\n",
    "# Вычисляем среднее арифметическое\n",
    "average_bleu, average_meteor, average_rouge_1, average_rouge_2, average_rouge_l, average, average_art_met = calculate_average(metrics)\n",
    "\n",
    "# Выводим среднее арифметическое\n",
    "print(\"Среднее арифметическое для BLEU score:\", average_bleu)\n",
    "print(\"Среднее арифметическое для METEOR score:\", average_meteor)\n",
    "print(\"Среднее арифметическое для ROUGE-1:\", average_rouge_1)\n",
    "print(\"Среднее арифметическое для ROUGE-2:\", average_rouge_2)\n",
    "print(\"Среднее арифметическое для ROUGE-L:\", average_rouge_l)\n",
    "print(\"Среднее арифметическое из всех метрик:\", average)\n",
    "print(\"Оценка качества перевода:\", average_art_met)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "import os\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from rouge import Rouge\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "\n",
    "def load_file(entry):\n",
    "    filepath = filedialog.askopenfilename(filetypes=[(\"Text files\", \"*.txt\")])\n",
    "    if filepath:\n",
    "        entry.delete(0, tk.END)\n",
    "        entry.insert(0, filepath)\n",
    "\n",
    "def process_files():\n",
    "    ref_path = entry_ref.get()\n",
    "    trans_path = entry_trans.get()\n",
    "\n",
    "    if not ref_path or not trans_path:\n",
    "        messagebox.showerror(\"Ошибка\", \"Необходимо загрузить оба файла\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Загрузка и обработка текстов\n",
    "        reference_text = load_text_preprocessed(ref_path)\n",
    "        translated_text = load_text_preprocessed(trans_path)\n",
    "\n",
    "        # Подсчет метрик и вывод результатов\n",
    "        calculate_and_display_metrics(reference_text, translated_text)\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Ошибка при обработке файлов\", str(e))\n",
    "\n",
    "def calculate_and_display_metrics(ref_text, trans_text):\n",
    "    # Токенизация текстов\n",
    "    reference_tokens = word_tokenize(ref_text.lower())\n",
    "    translated_tokens = word_tokenize(trans_text.lower())\n",
    "\n",
    "    # Вычисление BLEU-метрики\n",
    "    bleu_score = corpus_bleu([[reference_tokens]], [translated_tokens])\n",
    "\n",
    "    # Создание экземпляра класса Rouge\n",
    "    rouge = Rouge()\n",
    "\n",
    "    # Вычисление метрики ROUGE\n",
    "    scores = rouge.get_scores(trans_text, ref_text)\n",
    "\n",
    "    # Оценка качества перевода с помощью метрики METEOR\n",
    "    meteor_score_value = meteor_score([reference_tokens], translated_tokens)\n",
    "\n",
    "    # Выбор весов для каждой метрики в зависимости от типа текста\n",
    "    if metric_type.get() == 'art':\n",
    "        w_bleu, w_rouge_1, w_score = 0.10, 0.50, 0.40\n",
    "    elif metric_type.get() == 'tech':\n",
    "        w_bleu, w_rouge_1, w_score = 0.20, 0.40, 0.40\n",
    "    elif metric_type.get() == 'doc':\n",
    "        w_bleu, w_rouge_1, w_score = 0.20, 0.45, 0.35\n",
    "\n",
    "    # Вычисление новой художественной метрики с весами\n",
    "    art_met = w_bleu * bleu_score + w_rouge_1 * scores[0]['rouge-1']['f'] + w_score * meteor_score_value\n",
    "\n",
    "    # Вывод результатов\n",
    "    result_text = f\"BLEU score: {bleu_score:.3f}\\n\"\n",
    "    result_text += f\"ROUGE scores: {scores[0]['rouge-1']['f']:.3f}, {scores[0]['rouge-2']['f']:.3f}, {scores[0]['rouge-l']['f']:.3f}\\n\"\n",
    "    result_text += f\"METEOR score: {meteor_score_value:.3f}\\n\"\n",
    "    result_text += f\"Оценка качества перевода (Выбранная метрика): {art_met:.3f}\\n\"\n",
    "    \n",
    "    text_widget.delete('1.0', tk.END)\n",
    "    text_widget.insert(tk.END, result_text)\n",
    "\n",
    "def load_text_preprocessed(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    return text\n",
    "\n",
    "# Настройка основного окна\n",
    "root = tk.Tk()\n",
    "root.title(\"MetriX\")\n",
    "\n",
    "# Настройка фрейма для загрузки файлов\n",
    "frame = tk.Frame(root)\n",
    "frame.pack(pady=20)\n",
    "\n",
    "entry_ref = tk.Entry(frame, width=50)\n",
    "entry_ref.pack(side=tk.LEFT, padx=(0, 10))\n",
    "button_ref = tk.Button(frame, text=\"Загрузить файл профессионального перевода\", command=lambda: load_file(entry_ref))\n",
    "button_ref.pack(side=tk.LEFT)\n",
    "\n",
    "frame_trans = tk.Frame(root)\n",
    "frame_trans.pack(pady=10)\n",
    "\n",
    "entry_trans = tk.Entry(frame_trans, width=50)\n",
    "entry_trans.pack(side=tk.LEFT, padx=(0, 10))\n",
    "button_trans = tk.Button(frame_trans, text=\"Загрузить файл системы машинного перевода\", command=lambda: load_file(entry_trans))\n",
    "button_trans.pack(side=tk.LEFT)\n",
    "\n",
    "# Добавляем выбор метрики\n",
    "metric_type = tk.StringVar(value='art')\n",
    "frame_metric = tk.Frame(root)\n",
    "frame_metric.pack(pady=10)\n",
    "tk.Label(frame_metric, text=\"Выберите тип текста:\").pack(side=tk.LEFT, padx=(0, 10))\n",
    "tk.Radiobutton(frame_metric, text=\"Художественный текст\", variable=metric_type, value='art').pack(side=tk.LEFT)\n",
    "tk.Radiobutton(frame_metric, text=\"Технический текст\", variable=metric_type, value='tech').pack(side=tk.LEFT)\n",
    "tk.Radiobutton(frame_metric, text=\"Документационный текст\", variable=metric_type, value='doc').pack(side=tk.LEFT)\n",
    "\n",
    "process_button = tk.Button(root, text=\"Обработать и показать метрики\", command=process_files)\n",
    "process_button.pack(pady=20)\n",
    "\n",
    "# Текстовый виджет для вывода результатов\n",
    "text_widget = tk.Text(root, height=15, width=80)\n",
    "text_widget.pack(pady=10)\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
